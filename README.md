# âš½ Sports Data Warehouse â€“ API-Football

Proyecto de **Data Engineering** endâ€‘toâ€‘end que construye un **Data Warehouse en estrella** a partir de datos deportivos obtenidos desde **APIâ€‘Football**, aplicando buenas prÃ¡cticas de **ETL, modelado dimensional, data quality y analytics SQL**.

> Objetivo: demostrar cÃ³mo pasar de una API cruda a un warehouse listo para BI y anÃ¡lisis, con foco en diseÃ±o y confiabilidad de datos.

---

## ðŸ§  Arquitectura general

```
API-Football
     â†“
Raw Layer (JSON particionado)
     â†“
Staging Layer (DuckDB)
     â†“
Warehouse (Modelo estrella)
     â†“
Analytics SQL (BI)
```

* **Fuente**: API-Football (REST)
* **Storage**: archivos JSON + DuckDB
* **Lenguaje**: Python + SQL
* **Modelo**: Star Schema

---

## ðŸ“ Estructura del proyecto

```
Sports-Data-Warehouse/
â”‚
â”œâ”€â”€ raw/                    # JSON crudos desde la API
â”‚   â””â”€â”€ api_football/
â”‚
â”œâ”€â”€ staging/                # DuckDB de staging
â”‚   â””â”€â”€ staging.duckdb
â”‚
â”œâ”€â”€ warehouse/              # DuckDB final (analytics-ready)
â”‚   â””â”€â”€ warehouse.duckdb
â”‚
â”œâ”€â”€ etl/
â”‚   â”œâ”€â”€ extract/            # Scripts de extracciÃ³n API â†’ JSON
â”‚   â”œâ”€â”€ sql/
â”‚   â”‚   â”œâ”€â”€ stg_*.sql       # Transformaciones de staging
â”‚   â”‚   â”œâ”€â”€ dim_*.sql       # Dimensiones
â”‚   â”‚   â””â”€â”€ fact_*.sql      # Tabla de hechos
â”‚   â”œâ”€â”€ load_staging.py
â”‚   â””â”€â”€ load_warehouse.py
â”‚
â”œâ”€â”€ etl/checks/             # Data Quality checks
â”‚   â”œâ”€â”€ data_quality_critical.sql
â”‚   â””â”€â”€ data_quality_warning.sql
â”‚
â”œâ”€â”€ analytics/              # Queries BI
â”‚   â”œâ”€â”€ top_scorers.sql
â”‚   â”œâ”€â”€ goals_per_90.sql
â”‚   â”œâ”€â”€ top_rated_players.sql
â”‚   â””â”€â”€ team_offense.sql
â”‚
â””â”€â”€ README.md
```

---

## ðŸ§± Modelo de datos

### â­ Dimensiones

* **dim_player**: informaciÃ³n del jugador
* **dim_team**: equipos
* **dim_league**: ligas
* **dim_date**: calendario (generado)

### ðŸ“Š Hechos

* **fact_player_stats**

  * MÃ©tricas: minutes, goals, assists, rating, appearances
  * Grano: *jugador â€“ equipo â€“ liga â€“ temporada*

---

## ðŸ”„ ETL Flow

### 1ï¸âƒ£ Extract

* Consumo de endpoints de APIâ€‘Football (`players`, `teams`, `leagues`, `fixtures`, etc.)
* Persistencia en **JSON particionado** por league, season y snapshot

### 2ï¸âƒ£ Staging

* Lectura de mÃºltiples JSON con `read_json_auto`
* NormalizaciÃ³n de estructuras anidadas
* Limpieza de tipos y valores inconsistentes

### 3ï¸âƒ£ Warehouse

* ConstrucciÃ³n de dimensiones con **surrogate keys**
* Hechos referenciando dimensiones
* Modelo estrella optimizado para BI

---

## ðŸ§ª Data Quality

Se implementaron checks automÃ¡ticos separados por severidad:

### âœ… Critical checks

* Claves nulas en dimensiones
* Claves forÃ¡neas huÃ©rfanas en la fact table

### âš ï¸ Warning checks

* Minutos invÃ¡lidos (>120 o <0)

Ejemplo de output:

```
ðŸ§ª Results from data_quality_critical.sql
fact_player_stats - orphan team_key: 0

ðŸ§ª Results from data_quality_warning.sql
fact_player_stats - invalid minutes: 8
```

---

## ðŸ“Š Analytics (BI)

Ejemplos de consultas incluidas:

* Top goleadores por temporada
* Goles por 90 minutos (eficiencia)
* Jugadores mejor calificados
* ProducciÃ³n ofensiva por equipo

Todas las queries viven en la carpeta `analytics/` y se ejecutan directamente sobre el warehouse.

---

## ðŸš€ CÃ³mo ejecutar el proyecto

```bash
# activar entorno virtual
source .venv/bin/activate

# cargar staging
python etl/load_staging.py

# construir warehouse
python etl/load_warehouse.py

# ejecutar checks de calidad
python etl/run_quality_checks.py
```

---

## ðŸ ConclusiÃ³n

Este proyecto replica un flujo real de **Data Engineering**, enfatizando:

* DiseÃ±o de datos antes que cÃ³digo
* SeparaciÃ³n clara de capas
* Control de calidad
* SQL orientado a negocio

Ideal como **proyecto de portfolio** para roles de Data Engineer / Analytics Engineer.

---

ðŸ“Œ *Datos con pelota, pero ingenierÃ­a en serio.*

